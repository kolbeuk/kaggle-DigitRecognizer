{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each image is 28 pixels in height and 28 pixels in width\n",
    "# total of 784 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../../data/digitrecognizer/test.csv\")\n",
    "train = pd.read_csv(\"../../data/digitrecognizer/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.info(), test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split label and feature data\n",
    "train_labels = (train['label'])\n",
    "train_features = (train.iloc[:, 1:].values).astype('float32')\n",
    "test_features = (test.values).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 28, 28, 1), (28000, 28, 28, 1), (42000,))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape into pixel dimensions and 1 column for gray scale\n",
    "train_features = train_features.reshape(train_features.shape[0], 28, 28, 1)\n",
    "test_features = test_features.reshape(test_features.shape[0], 28, 28, 1)\n",
    "train_features.shape, test_features.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample digits \n",
    "for i in range(16, 7):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(train_features[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(train_labels[i]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.countplot(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisation of the data so its between 0 and 1\n",
    "train_features = train_features.astype('float32')/255.\n",
    "test_features = test_features.astype('float32')/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the target labels to categorical \n",
    "train_labels = to_categorical(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37800, 28, 28, 1), (4200, 28, 28, 1), (37800, 10), (4200, 10))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_labels, test_size=0.10, random_state=42)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the basic CNN\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 3), \n",
    "                    activation='relu', \n",
    "                    input_shape=(28, 28, 1)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=1e-4), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 852,906\n",
      "Trainable params: 852,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/12\n",
      "  128/37800 [..............................] - ETA: 2:04"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must be broadcastable: logits_size=[128,10] labels_size=[5120,2]\n\t [[node loss/dense_21_loss/softmax_cross_entropy_with_logits (defined at <ipython-input-179-3d180c8076ca>:10) ]] [Op:__inference_distributed_function_10311]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-3d180c8076ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           validation_data=(X_val, Y_val))\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  logits and labels must be broadcastable: logits_size=[128,10] labels_size=[5120,2]\n\t [[node loss/dense_21_loss/softmax_cross_entropy_with_logits (defined at <ipython-input-179-3d180c8076ca>:10) ]] [Op:__inference_distributed_function_10311]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "# fit the model \n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_train, Y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_train, Y_train, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "history_dict = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=model.predict(test_features)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
